{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT2020116_ML Assignment 2_Q1(part - II).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4YUtyX0LDR"
      },
      "source": [
        "#i) Plot a graph of accuracy vs. the number of hidden units.(64,128,256,512)\n",
        "#ii) Plot a graph of accuracy vs. activation function.(Relu,logistic sigmoid,tanh,leaky Relu)\n",
        "#iii) Plot a graph comparing the following three loss functions vs accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y2D4teeDKQh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "8XGOMyF2Dxk7",
        "outputId": "08622893-66a6-4711-ba41-979793a4c6aa"
      },
      "source": [
        "\n",
        "\n",
        "#Check observation one by one different dataset remove comment part and see observations\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/psantul/Dataset/main/data.csv\", encoding='latin-1')\n",
        "#data = pd.read_csv(\"https://raw.githubusercontent.com/psantul/Dataset/main/titanic.csv\",delimiter = ',', encoding='latin-1')\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0V56ipl0LDZ"
      },
      "source": [
        "x = data.iloc[:,3:].values\n",
        "y = data.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5qywpYu0LDb"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2BvzB9IMwPO"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfvj1ojoPOk1",
        "outputId": "02eaf5c1-cf5d-4080-8c8c-94064962e7a0"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 29)\n",
            "(455,)\n",
            "(114, 29)\n",
            "(114,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eesahMST0Rd"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PLmTy5BXyHh",
        "outputId": "52d40f99-ce6e-45b9-fc9b-0abcc6ac039d"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8a2A8mxPP6Y"
      },
      "source": [
        "nn_input_dim = X_train.shape[1]\n",
        "nn_output_dim = len(np.unique(y_train))\n",
        "lr = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOOxUS2SPV2e"
      },
      "source": [
        "# helper function to calculate total loss on the dataset\n",
        "def calculate_loss(model, X, y):\n",
        "  num_examples = X.shape[0]\n",
        "  W1 = model['W1']\n",
        "  b1 = model['b1']\n",
        "  W2 = model['W2']\n",
        "  b2 = model['b2']\n",
        "  # forward propagation to calculate out predictions\n",
        "  z1 = X.dot(W1) + b1\n",
        "  a1 = np.tanh(z1)\n",
        "  z2 = a1.dot(W2) + b2\n",
        "  exp_scores = np.exp(z2)\n",
        "  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "  # Calculating the loss\n",
        "  corect_logprobs = -np.log(probs[range(num_examples), y])\n",
        "  data_loss = np.sum(corect_logprobs)\n",
        "  return 1. / num_examples * data_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZDUsp6bPXBR"
      },
      "source": [
        "def predict(model, x):\n",
        "  W1 = model['W1']\n",
        "  b1 = model['b1']\n",
        "  W2 = model['W2']\n",
        "  b2 = model['b2']\n",
        "  \n",
        "\n",
        "  # Forward propagation\n",
        "  z1 = x.dot(W1) + b1\n",
        "  a1 = np.tanh(z1)\n",
        "  z2 = a1.dot(W2) + b2\n",
        "  exp_scores = np.exp(z2)\n",
        "  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "  return np.argmax(probs, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf4osImuPZxg"
      },
      "source": [
        "# (Relu,logistic sigmoid,tanh,leaky Relu) \n",
        "\n",
        "def relu(x):\n",
        "  x[x<0]=0\n",
        "  return x\n",
        "\n",
        "def logsig(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def leaky_relu(x):\n",
        "  x[x<0] *= 0.01\n",
        "  return x\n",
        "\n",
        "def build_model(X, y, nn_hdim, num_passes = 10000, print_loss=False):\n",
        "  \n",
        "  num_examples = X.shape[0]\n",
        "  np.random.seed(0)\n",
        "  W1 = np.random.rand(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n",
        "  b1 = np.zeros((1, nn_hdim))\n",
        "  W2 = np.random.rand(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n",
        "  b2 = np.zeros((1, nn_output_dim))\n",
        "  model = {}\n",
        "  losses = []\n",
        "  \n",
        "  # Gradient descent. for each batch\n",
        "  for i in range(0, num_passes):\n",
        "    \n",
        "    \n",
        "    # Forward propagation\n",
        "    z1 = X.dot(W1) + b1\n",
        "    a1 = tanh(z1)\n",
        "    z2 = a1.dot(W2) + b2\n",
        "    exp_scores = np.exp(z2)\n",
        "    probs = exp_scores / np.sum(np.array(exp_scores), axis=1, keepdims=True)\n",
        "\n",
        "    # Backpropagation\n",
        "    delta3 = np.array(probs)\n",
        "    delta3[range(num_examples), y] -= 1\n",
        "    dW2 = (a1.T).dot(delta3)\n",
        "    db2 = np.sum(delta3, axis=0, keepdims=True)\n",
        "    delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n",
        "    dW1 = np.dot(X.T, delta2)\n",
        "    db1 = np.sum(delta2, axis=0)\n",
        "\n",
        "    # Gradient descent parameter update\n",
        "    W1 += -lr * dW1\n",
        "    b1 += -lr * db1\n",
        "    W2 += -lr * dW2\n",
        "    b2 += -lr * db2\n",
        "    \n",
        "    \n",
        "    # Assign new parameters to the model\n",
        "    model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
        "    \n",
        "    if print_loss and i % 1000 == 0:\n",
        "      loss = calculate_loss(model, X, y)\n",
        "      losses.append(loss)\n",
        "      print(\"Loss after iteration %i: %f\" % (i, loss))\n",
        "\n",
        "  return model, losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "u1pA61QoPbd3",
        "outputId": "ceed7556-bcc2-4094-aea1-3909dd47139e"
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for nodes in [64, 128, 256, 512]:\n",
        "  print('\\n for {} number of nodes'.format(nodes))\n",
        "  model, loss = build_model((X_train),(y_train), nodes, print_loss=True)\n",
        "  preds = predict(model, X_test)\n",
        "  acc = ((preds == y_test).sum() / len(y_test)) * 100\n",
        "  x.append(nodes)\n",
        "  y.append(acc)\n",
        "\n",
        "plt.xlabel('number of nodes')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('using {} activation function'.format('leaky_relu'))  # place of relu changes logsig,tanh,leaky_relu: Different loss result shown in graph and accuracy\n",
        "plt.plot(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " for 64 number of nodes\n",
            "Loss after iteration 0: 34.857809\n",
            "Loss after iteration 1000: 39.801998\n",
            "Loss after iteration 2000: 78.826098\n",
            "Loss after iteration 3000: 38.325864\n",
            "Loss after iteration 4000: 74.413021\n",
            "Loss after iteration 5000: 96.303422\n",
            "Loss after iteration 6000: 79.858234\n",
            "Loss after iteration 7000: 76.138892\n",
            "Loss after iteration 8000: 13.618923\n",
            "Loss after iteration 9000: 132.255921\n",
            "\n",
            " for 128 number of nodes\n",
            "Loss after iteration 0: 70.733648\n",
            "Loss after iteration 1000: 9.831349\n",
            "Loss after iteration 2000: 6.627268\n",
            "Loss after iteration 3000: 202.946604\n",
            "Loss after iteration 4000: 185.200636\n",
            "Loss after iteration 5000: 22.813713\n",
            "Loss after iteration 6000: 57.549170\n",
            "Loss after iteration 7000: 81.761277\n",
            "Loss after iteration 8000: 182.897264\n",
            "Loss after iteration 9000: 187.984353\n",
            "\n",
            " for 256 number of nodes\n",
            "Loss after iteration 0: 73.987556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-14-85efc97c068e>:36: RuntimeWarning: overflow encountered in exp\n",
            "  exp_scores = np.exp(z2)\n",
            "<ipython-input-14-85efc97c068e>:37: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probs = exp_scores / np.sum(np.array(exp_scores), axis=1, keepdims=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss after iteration 1000: nan\n",
            "Loss after iteration 2000: nan\n",
            "Loss after iteration 3000: nan\n",
            "Loss after iteration 4000: nan\n",
            "Loss after iteration 5000: nan\n",
            "Loss after iteration 6000: nan\n",
            "Loss after iteration 7000: nan\n",
            "Loss after iteration 8000: nan\n",
            "Loss after iteration 9000: nan\n",
            "\n",
            " for 512 number of nodes\n",
            "Loss after iteration 0: 136.086092\n",
            "Loss after iteration 1000: nan\n",
            "Loss after iteration 2000: nan\n",
            "Loss after iteration 3000: nan\n",
            "Loss after iteration 4000: nan\n",
            "Loss after iteration 5000: nan\n",
            "Loss after iteration 6000: nan\n",
            "Loss after iteration 7000: nan\n",
            "Loss after iteration 8000: nan\n",
            "Loss after iteration 9000: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x24fb82259a0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpxrGBqxPeOK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}